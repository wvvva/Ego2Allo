{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80f0f34",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SAT_raw_predictions_gemini_2.5_flash_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAT_raw_predictions_gemini_2.5_flash_0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m SAT_DATASET_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ocean/projects/cis250208p/shared/datasets/SAT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/apc_vlm_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apc_vlm_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/apc_vlm_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apc_vlm_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/apc_vlm_env/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SAT_raw_predictions_gemini_2.5_flash_0.csv'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "file_path = \"SAT_raw_predictions_gemini_2.5_flash_0.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"SAT_labeled.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "ds = ds.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8ec6a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, False, True, True, False, True, True, True, True, True, False, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, False, True, True, False, True, False, True, True, False, True, True, False, True, True, True, True, True, True, False, False, True, True, False, False, False, True, True, False, True, False, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "match_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    pred = df.iloc[i][\"prediction\"]\n",
    "    if not isinstance(pred, str) or len(pred.strip()) == 0:\n",
    "        match_list.append(False)\n",
    "        continue\n",
    "\n",
    "    pred_index = ord(pred) - ord('A')\n",
    "    if pred_index < 0 or pred_index >= len(ds[i][\"answer_choices\"]):\n",
    "        match_list.append(False)\n",
    "        continue\n",
    "    answer = ds[i][\"answer_choices\"][pred_index]\n",
    "    if answer == ds[i][\"correct_answer\"]:\n",
    "        match_list.append(True)\n",
    "    else:\n",
    "        match_list.append(False)\n",
    "\n",
    "print(match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c5d00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 66 out of 100\n"
     ]
    }
   ],
   "source": [
    "# count the number of matches\n",
    "matched = sum(match_list)\n",
    "print(f\"Matched {matched} out of {len(df)}\")\n",
    "\n",
    "# count the number of matches for each question\n",
    "question_matches = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875b76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index             category  \\\n",
      "0      0  DISTANCE_COMPARISON   \n",
      "1      1    RELATIVE_LOCATION   \n",
      "2      2    RELATIVE_LOCATION   \n",
      "3      3    RELATIVE_LOCATION   \n",
      "4      4    RELATIVE_LOCATION   \n",
      "\n",
      "                                            question  \\\n",
      "0  Which point is closer to the camera taking thi...   \n",
      "1  Considering the relative positions, is iron ch...   \n",
      "2  Considering the relative positions, where is b...   \n",
      "3  Considering the relative positions, is extenda...   \n",
      "4  Considering the relative positions, where is s...   \n",
      "\n",
      "                                           reasoning prediction answer  \\\n",
      "0  The image shows a perspective view where objec...          B      C   \n",
      "1  The image shows a perspective view of a 3D sce...          A  below   \n",
      "2  The image shows a single 3D object that appear...        NaN  right   \n",
      "3  The image depicts a 3D scene with a vanishing ...          B  below   \n",
      "4  The image shows a colorful landscape painting ...          A  right   \n",
      "\n",
      "   is_correct                                      response_text  \n",
      "0       False  [Reasoning] The image shows a perspective view...  \n",
      "1       False  [Reasoning] The image shows a perspective view...  \n",
      "2       False  [Reasoning] The image shows a single 3D object...  \n",
      "3       False  [Reasoning] The image depicts a 3D scene with ...  \n",
      "4       False  [Reasoning] The image shows a colorful landsca...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de27f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "SAT_TRAIN_GENERATED_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT/train_generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c3282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global image_idx_counter\n",
    "image_idx_counter = 0\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def base64_to_image(base64_str: str) -> Image.Image:\n",
    "    \"\"\"Convert a base64 string back to a PIL Image.\"\"\"\n",
    "    img_data = base64.b64decode(base64_str)\n",
    "    return Image.open(BytesIO(img_data))\n",
    "\n",
    "def deserialize_messages_to_image_paths(serialized):\n",
    "    \"\"\"Convert base64-encoded images in messages back to PIL Images.\"\"\"\n",
    "    global image_idx_counter\n",
    "    deserialized = []\n",
    "    for msg in serialized:\n",
    "        new_msg = {\"role\": msg[\"role\"], \"content\": []}\n",
    "        for i, item in enumerate(msg[\"content\"]):\n",
    "            if item[\"type\"] == \"image\" and \"data\" in item:\n",
    "                # Reconstruct PIL image from base64 data\n",
    "                image = base64_to_image(item[\"data\"])\n",
    "                image_path = f\"{SAT_TRAIN_GENERATED_FOLDER}/images/image_{image_idx_counter}.png\"\n",
    "                image.save(image_path)\n",
    "                image_idx_counter += 1\n",
    "                new_msg[\"content\"].append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image_path\n",
    "                })\n",
    "                msg[\"content\"][i + 1][\"text\"] = msg[\"content\"][i + 1][\"text\"]\n",
    "            else:\n",
    "                new_msg[\"content\"].append(item)\n",
    "        deserialized.append(new_msg)\n",
    "    return deserialized\n",
    "\n",
    "def deserialize_messages_to_image(serialized):\n",
    "    \"\"\"Convert base64-encoded images in messages back to PIL Images.\"\"\"\n",
    "    global image_idx_counter\n",
    "    deserialized = []\n",
    "    for msg in serialized:\n",
    "        new_msg = {\"role\": msg[\"role\"], \"content\": []}\n",
    "        for i, item in enumerate(msg[\"content\"]):\n",
    "            if item[\"type\"] == \"image\" and \"data\" in item:\n",
    "                # Reconstruct PIL image from base64 data\n",
    "                image = base64_to_image(item[\"data\"])\n",
    "                new_msg[\"content\"].append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image\n",
    "                })\n",
    "            else:\n",
    "                new_msg[\"content\"].append(item)\n",
    "        deserialized.append(new_msg)\n",
    "    return deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3d10bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SAT_TRAIN_GENERATED_FOLDER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mSAT_TRAIN_GENERATED_FOLDER\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation_1.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(json\u001b[38;5;241m.\u001b[39mloads(line))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SAT_TRAIN_GENERATED_FOLDER' is not defined"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(os.path.join(SAT_TRAIN_GENERATED_FOLDER, \"conversation_1.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "deserialized = deserialize_messages_to_image(data[0][\"messages\"])\n",
    "print(deserialized)\n",
    "# deserialized[0][\"content\"][0][\"image\"].save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c3aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_data(entry):\n",
    "    processed_entry = {}\n",
    "    deserialized = deserialize_messages_to_image_paths(entry[\"messages\"])\n",
    "    processed_entry[\"messages\"] = deserialized\n",
    "    processed_entry[\"response\"] = entry[\"response\"]\n",
    "    processed_entry[\"conv_type\"] = entry[\"conv_type\"]\n",
    "    return processed_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e2390bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/591 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither above nor below\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 21/591 [00:03<01:26,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither A nor B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 26/591 [00:04<01:48,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither A nor B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 33/591 [00:05<01:45,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no black metal chair (highlighted by a red box) in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 39/591 [00:06<01:29,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 60/591 [00:11<01:32,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question is based on a false premise as there is only one cube, which is green with a yellow top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 147/591 [00:31<01:14,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither A nor B can be definitively chosen as they are at the same level\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 170/591 [00:36<01:49,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no brown burgundy leather sofa in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 242/591 [00:52<01:01,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no point b in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 245/591 [00:53<01:14,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no brown square dining table in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 322/591 [01:10<01:10,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as posed because there is only one cube object visible in the image, and it has both green and yellow components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 368/591 [01:23<00:41,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 407/591 [01:32<00:35,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 417/591 [01:34<00:31,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither above nor below\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 449/591 [01:40<00:34,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no black wooden shelving unit in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 463/591 [01:42<00:16,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no brown square dresser in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 515/591 [01:54<00:22,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no chair (marked b) in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 522/591 [01:55<00:09,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no blue framed coastal marine wall decor in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 568/591 [02:07<00:04,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No teddybear is highlighted in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 576/591 [02:09<00:02,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 583/591 [02:10<00:01,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither A nor B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591/591 [02:12<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6277495769881557\n",
      "371\n",
      "591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"SAT_labeled.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "SAT_TRAIN_GENERATED_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT/train_generated_2\"\n",
    "\n",
    "correct_idx = []\n",
    "total_count = 0\n",
    "\n",
    "image_idx_counter = 0\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "files = os.listdir(SAT_TRAIN_GENERATED_FOLDER)\n",
    "files = [f for f in files if f.endswith(\".jsonl\")]\n",
    "\n",
    "total_count = len(files)\n",
    "for filename in tqdm(files):\n",
    "    idx = int(filename.split(\"_\")[-1].split(\".\")[0])\n",
    "    file_path = os.path.join(SAT_TRAIN_GENERATED_FOLDER, filename)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = []\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "        try:\n",
    "            answer_extracted = data[-1][\"response\"].split(\"[Answer]\")[1].strip()\n",
    "            answer_extracted = answer_extracted.split(\".\")[0].strip()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    \n",
    "        try:\n",
    "            pred_index = ord(answer_extracted) - ord('A')\n",
    "        except:\n",
    "            print(answer_extracted)\n",
    "            continue\n",
    "\n",
    "        if pred_index < 0 or pred_index >= len(ds[idx][\"answer_choices\"]):\n",
    "            continue\n",
    "        answer = ds[idx][\"answer_choices\"][pred_index]\n",
    "        if answer == ds[idx][\"correct_answer\"]:\n",
    "            correct_idx.append(idx)\n",
    "            for item in data:\n",
    "                processed_data.append(parse_image_data(item))\n",
    "                # processed_data.append(item)\n",
    "            \n",
    "print(len(correct_idx)/total_count)\n",
    "print(len(correct_idx))\n",
    "print(total_count)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648bb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'user', 'content': [{'type': 'image', 'image': '/ocean/projects/cis250208p/shared/datasets/SAT/train_generated/images/image_0.png'}, {'type': 'text', 'text': \"<image>\\n### Situation Description\\nGiven an image and a spatial reasoning question, we need to all entities that are included in the question.\\n\\n# Example 1\\n[Question] You are standing at the airplane's position, facing where it is facing. Is the the person on your left or right?\\n[Detect] [airplane, person]\\n\\n# Examples 2\\n[Question] From the old man's perspective, is the person wearing a hat on the left of the green car?\\n[Detect] [old man, person wearing a hat, green car]\\n\\n# Examples 3\\n[Question] From the car's perspective, which is on the right side: the person or the tree?\\n[Detect] [car, person, tree]\\n\\n### Your Task\\nNow, given the question below, please identify the entities that are included in the question.\\n\\n[Question] From the camera's point of view, Considering the relative positions, is wooden dining table (marked C) above or below AlarmClock (marked B)? A. above or B. below, give the letter of the correct answer.\\n[Detect]\\n\"}]}], 'response': '[camera, wooden dining table, AlarmClock]', 'conv_type': 'get_objects_of_interest'}\n"
     ]
    }
   ],
   "source": [
    "print(processed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb026b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsloth Format\n",
    "def unsloth_format(processed_data):\n",
    "    output_data = []\n",
    "\n",
    "    conv_type_counter = {\n",
    "    }\n",
    "\n",
    "    for item in processed_data:\n",
    "        \n",
    "        if item[\"conv_type\"] not in conv_type_counter:\n",
    "            conv_type_counter[item[\"conv_type\"]] = 0\n",
    "        conv_type_counter[item[\"conv_type\"]] += 1\n",
    "\n",
    "        entry = {\n",
    "            \"messages\": [],\n",
    "        }\n",
    "\n",
    "        for msg in item[\"messages\"]:\n",
    "            e = {\n",
    "                \"role\": msg[\"role\"],\n",
    "                \"content\": []\n",
    "            }\n",
    "            for content in msg[\"content\"]:\n",
    "                if content[\"type\"] == \"image\":\n",
    "                    e[\"content\"].append({\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": content[\"image\"]\n",
    "                    })\n",
    "                elif content[\"type\"] == \"text\":\n",
    "                    e[\"content\"].append({\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": content[\"text\"]\n",
    "                    })\n",
    "                else:\n",
    "                    print(\"Unknown content type\")\n",
    "\n",
    "            if len(e[\"content\"]) == 2:\n",
    "                temp = e[\"content\"][0]\n",
    "                e[\"content\"][0] = e[\"content\"][1]\n",
    "                e[\"content\"][1] = temp\n",
    "\n",
    "            entry[\"messages\"].append(e)\n",
    "\n",
    "        entry[\"messages\"].append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": item[\"response\"]\n",
    "            }]\n",
    "        })\n",
    "\n",
    "        output_data.append(entry)\n",
    "    print(conv_type_counter)\n",
    "\n",
    "    return output_data, conv_type_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79be404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpareGPT format\n",
    "def sparegpt_format(processed_data):\n",
    "\n",
    "    output_data = []\n",
    "\n",
    "    conv_type_counter = {\n",
    "    }\n",
    "\n",
    "    for item in processed_data:\n",
    "        \n",
    "        if item[\"conv_type\"] not in conv_type_counter:\n",
    "            conv_type_counter[item[\"conv_type\"]] = 0\n",
    "        conv_type_counter[item[\"conv_type\"]] += 1\n",
    "\n",
    "        entry = {\n",
    "            \"messages\": [],\n",
    "            \"images\": [],\n",
    "        }\n",
    "\n",
    "        for msg in item[\"messages\"]:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                for sub_item in msg[\"content\"]:\n",
    "                    if sub_item[\"type\"] == \"image\":\n",
    "                        entry[\"images\"].append(sub_item[\"image\"])\n",
    "                    elif sub_item[\"type\"] == \"text\":\n",
    "                        entry[\"messages\"].append({\n",
    "                            \"content\": sub_item[\"text\"],\n",
    "                            \"role\": \"user\"\n",
    "                        })\n",
    "                    else:\n",
    "                        print(\"Unknown message type\")\n",
    "            elif msg[\"role\"] == \"system\":\n",
    "                if len(msg[\"content\"]) != 1:\n",
    "                    print(\"ERROR\")\n",
    "\n",
    "                entry[\"messages\"].append({\n",
    "                    \"content\": msg[\"content\"][0][\"text\"],\n",
    "                    \"role\": \"assistant\"\n",
    "                })\n",
    "            else:\n",
    "                print(\"Unknown message role\")\n",
    "        \n",
    "        entry[\"messages\"].append({\n",
    "            \"content\": item[\"response\"],\n",
    "            \"role\": \"assistant\"\n",
    "        })\n",
    "            \n",
    "        output_data.append(entry)\n",
    "\n",
    "    print(conv_type_counter)\n",
    "\n",
    "    return output_data, conv_type_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70caf367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_objects_of_interest': 371, 'detection_refinement': 771, 'get_reference_viewer': 371, 'convert_to_ego': 371, 'perspective_visual': 371, 'abstract_to_real': 371}\n"
     ]
    }
   ],
   "source": [
    "output_data, conv_type_counter = unsloth_format(processed_data)\n",
    "\n",
    "with open(SAT_TRAIN_GENERATED_FOLDER + \"/train_data.json\", \"w\") as f:\n",
    "    json.dump(output_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5e1e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3663\n"
     ]
    }
   ],
   "source": [
    "print(image_idx_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15ee102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets\"\n",
    "# with open(os.path.join(SAT_DATASET_FOLDER, \"data.json\"), \"w\") as f:\n",
    "\n",
    "merge_data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"train_generated/train_data.json\"), \"r\") as f:\n",
    "    merge_data.extend(json.load(f))\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"train_generated_1/train_data.json\"), \"r\") as f:\n",
    "    merge_data.extend(json.load(f))\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"train_generated_2/train_data.json\"), \"r\") as f:\n",
    "    merge_data.extend(json.load(f))\n",
    "\n",
    "with open(os.path.join(DATASET_FOLDER, \"data.json\"), \"w\") as f:\n",
    "    json.dump(merge_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7fe62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATASET_FOLDER, \"SAT_processed/data.json\"), \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATASET_FOLDER, \"SAT_processed/test.json\"), \"w\") as f:\n",
    "    json.dump(data[0], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8aba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"/ocean/projects/cis250208p/shared/datasets/data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# shuffle data\n",
    "random.shuffle(data)\n",
    "\n",
    "# split data into train and test\n",
    "train_data = data[:int(len(data)*0.9)]\n",
    "test_data = data[int(len(data)*0.9):]\n",
    "\n",
    "with open(\"/ocean/projects/cis250208p/shared/datasets/train_data.json\", \"w\") as f:\n",
    "    json.dump(train_data, f, indent=2)\n",
    "\n",
    "with open(\"/ocean/projects/cis250208p/shared/datasets/test_data.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
