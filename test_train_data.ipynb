{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a80f0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "file_path = \"SAT_raw_predictions_gemini_2.5_flash_0.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"SAT_labeled.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "ds = ds.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8ec6a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, False, True, True, False, True, True, True, True, True, False, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, False, True, True, False, True, False, True, True, False, True, True, False, True, True, True, True, True, True, False, False, True, True, False, False, False, True, True, False, True, False, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "match_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    pred = df.iloc[i][\"prediction\"]\n",
    "    if not isinstance(pred, str) or len(pred.strip()) == 0:\n",
    "        match_list.append(False)\n",
    "        continue\n",
    "\n",
    "    pred_index = ord(pred) - ord('A')\n",
    "    if pred_index < 0 or pred_index >= len(ds[i][\"answer_choices\"]):\n",
    "        match_list.append(False)\n",
    "        continue\n",
    "    answer = ds[i][\"answer_choices\"][pred_index]\n",
    "    if answer == ds[i][\"correct_answer\"]:\n",
    "        match_list.append(True)\n",
    "    else:\n",
    "        match_list.append(False)\n",
    "\n",
    "print(match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c5d00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 66 out of 100\n"
     ]
    }
   ],
   "source": [
    "# count the number of matches\n",
    "matched = sum(match_list)\n",
    "print(f\"Matched {matched} out of {len(df)}\")\n",
    "\n",
    "# count the number of matches for each question\n",
    "question_matches = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875b76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index             category  \\\n",
      "0      0  DISTANCE_COMPARISON   \n",
      "1      1    RELATIVE_LOCATION   \n",
      "2      2    RELATIVE_LOCATION   \n",
      "3      3    RELATIVE_LOCATION   \n",
      "4      4    RELATIVE_LOCATION   \n",
      "\n",
      "                                            question  \\\n",
      "0  Which point is closer to the camera taking thi...   \n",
      "1  Considering the relative positions, is iron ch...   \n",
      "2  Considering the relative positions, where is b...   \n",
      "3  Considering the relative positions, is extenda...   \n",
      "4  Considering the relative positions, where is s...   \n",
      "\n",
      "                                           reasoning prediction answer  \\\n",
      "0  The image shows a perspective view where objec...          B      C   \n",
      "1  The image shows a perspective view of a 3D sce...          A  below   \n",
      "2  The image shows a single 3D object that appear...        NaN  right   \n",
      "3  The image depicts a 3D scene with a vanishing ...          B  below   \n",
      "4  The image shows a colorful landscape painting ...          A  right   \n",
      "\n",
      "   is_correct                                      response_text  \n",
      "0       False  [Reasoning] The image shows a perspective view...  \n",
      "1       False  [Reasoning] The image shows a perspective view...  \n",
      "2       False  [Reasoning] The image shows a single 3D object...  \n",
      "3       False  [Reasoning] The image depicts a 3D scene with ...  \n",
      "4       False  [Reasoning] The image shows a colorful landsca...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de27f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "SAT_TRAIN_GENERATED_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT/train_generated_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c3282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def base64_to_image(base64_str: str) -> Image.Image:\n",
    "    \"\"\"Convert a base64 string back to a PIL Image.\"\"\"\n",
    "    img_data = base64.b64decode(base64_str)\n",
    "    return Image.open(BytesIO(img_data))\n",
    "\n",
    "def deserialize_messages(serialized):\n",
    "    \"\"\"Convert base64-encoded images in messages back to PIL Images.\"\"\"\n",
    "    deserialized = []\n",
    "    for msg in serialized:\n",
    "        new_msg = {\"role\": msg[\"role\"], \"content\": []}\n",
    "        for item in msg[\"content\"]:\n",
    "            if item[\"type\"] == \"image\" and \"data\" in item:\n",
    "                # Reconstruct PIL image from base64 data\n",
    "                image = base64_to_image(item[\"data\"])\n",
    "                new_msg[\"content\"].append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image\n",
    "                })\n",
    "            else:\n",
    "                new_msg[\"content\"].append(item)\n",
    "        deserialized.append(new_msg)\n",
    "    return deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3d10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=400x400 at 0x7F88C8511340>}, {'type': 'text', 'text': \"\\n### Situation Description\\nGiven an image and a spatial reasoning question, we need to all entities that are included in the question.\\n\\n# Example 1\\n[Question] You are standing at the airplane's position, facing where it is facing. Is the the person on your left or right?\\n[Detect] [airplane, person]\\n\\n# Examples 2\\n[Question] From the old man's perspective, is the person wearing a hat on the left of the green car?\\n[Detect] [old man, person wearing a hat, green car]\\n\\n# Examples 3\\n[Question] From the car's perspective, which is on the right side: the person or the tree?\\n[Detect] [car, person, tree]\\n\\n### Your Task\\nNow, given the question below, please identify the entities that are included in the question.\\n\\n[Question] From the camera's point of view, Considering the relative positions, is iron cheir above or below Doorway? A. below or B. above, give the letter of the correct answer.\\n[Detect]\\n\"}]}]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(os.path.join(SAT_TRAIN_GENERATED_FOLDER, \"conversation_1.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "deserialized = deserialize_messages(data[0][\"messages\"])\n",
    "print(deserialized)\n",
    "# deserialized[0][\"content\"][0][\"image\"].save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e2390bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there are no separate gray rectangle sofa and green threecushion sofa in the image\n",
      "Cannot answer\n",
      "Cannot answer the question as there is no doorway in the image\n",
      "The question cannot be answered as posed because the red and green sections are part of a single object and are positioned side-by-side on the same horizontal plane, not one above or below the other\n",
      "No square cardboard box is visible in the image\n",
      "No brown wooden chair (marked b) is visible in the image\n",
      "Cannot answer\n",
      "The question cannot be answered as posed because there is no point a in the image\n",
      "There is no black chair with round backrest (marked a) in the image\n",
      "Cannot answer\n",
      "Neither A nor B can be definitively chosen as the objects are at the same depth\n",
      "The question cannot be answered as there is no doorway in the image\n",
      "0.642023346303502\n",
      "495\n",
      "771\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"SAT_labeled.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "SAT_TRAIN_GENERATED_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT/train_generated_1\"\n",
    "\n",
    "correct_idx = []\n",
    "total_count = 0\n",
    "\n",
    "for root, _, files in os.walk(SAT_TRAIN_GENERATED_FOLDER):\n",
    "    total_count = len(files)\n",
    "    for filename in files:\n",
    "        idx = int(filename.split(\"_\")[-1].split(\".\")[0])\n",
    "        file_path = os.path.join(root, filename)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "\n",
    "            try:\n",
    "                answer_extracted = data[-1][\"response\"].split(\"[Answer]\")[1].strip()\n",
    "                answer_extracted = answer_extracted.split(\".\")[0].strip()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        \n",
    "            try:\n",
    "                pred_index = ord(answer_extracted) - ord('A')\n",
    "            except:\n",
    "                print(answer_extracted)\n",
    "                continue\n",
    "\n",
    "            if pred_index < 0 or pred_index >= len(ds[idx][\"answer_choices\"]):\n",
    "                continue\n",
    "            answer = ds[idx][\"answer_choices\"][pred_index]\n",
    "            if answer == ds[idx][\"correct_answer\"]:\n",
    "                correct_idx.append(idx)\n",
    "\n",
    "print(len(correct_idx)/total_count)\n",
    "print(len(correct_idx))\n",
    "print(total_count)\n",
    "            \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
