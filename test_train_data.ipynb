{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a80f0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "file_path = \"SAT_raw_predictions_gemini_2.5_flash_0.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"SAT_labeled.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "ds = ds.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8ec6a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, False, True, True, False, True, True, True, True, True, False, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, False, True, True, False, True, False, True, True, False, True, True, False, True, True, True, True, True, True, False, False, True, True, False, False, False, True, True, False, True, False, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "match_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    pred = df.iloc[i][\"prediction\"]\n",
    "    if not isinstance(pred, str) or len(pred.strip()) == 0:\n",
    "        match_list.append(False)\n",
    "        continue\n",
    "\n",
    "    pred_index = ord(pred) - ord('A')\n",
    "    if pred_index < 0 or pred_index >= len(ds[i][\"answer_choices\"]):\n",
    "        match_list.append(False)\n",
    "        continue\n",
    "    answer = ds[i][\"answer_choices\"][pred_index]\n",
    "    if answer == ds[i][\"correct_answer\"]:\n",
    "        match_list.append(True)\n",
    "    else:\n",
    "        match_list.append(False)\n",
    "\n",
    "print(match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c5d00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 66 out of 100\n"
     ]
    }
   ],
   "source": [
    "# count the number of matches\n",
    "matched = sum(match_list)\n",
    "print(f\"Matched {matched} out of {len(df)}\")\n",
    "\n",
    "# count the number of matches for each question\n",
    "question_matches = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875b76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index             category  \\\n",
      "0      0  DISTANCE_COMPARISON   \n",
      "1      1    RELATIVE_LOCATION   \n",
      "2      2    RELATIVE_LOCATION   \n",
      "3      3    RELATIVE_LOCATION   \n",
      "4      4    RELATIVE_LOCATION   \n",
      "\n",
      "                                            question  \\\n",
      "0  Which point is closer to the camera taking thi...   \n",
      "1  Considering the relative positions, is iron ch...   \n",
      "2  Considering the relative positions, where is b...   \n",
      "3  Considering the relative positions, is extenda...   \n",
      "4  Considering the relative positions, where is s...   \n",
      "\n",
      "                                           reasoning prediction answer  \\\n",
      "0  The image shows a perspective view where objec...          B      C   \n",
      "1  The image shows a perspective view of a 3D sce...          A  below   \n",
      "2  The image shows a single 3D object that appear...        NaN  right   \n",
      "3  The image depicts a 3D scene with a vanishing ...          B  below   \n",
      "4  The image shows a colorful landscape painting ...          A  right   \n",
      "\n",
      "   is_correct                                      response_text  \n",
      "0       False  [Reasoning] The image shows a perspective view...  \n",
      "1       False  [Reasoning] The image shows a perspective view...  \n",
      "2       False  [Reasoning] The image shows a single 3D object...  \n",
      "3       False  [Reasoning] The image depicts a 3D scene with ...  \n",
      "4       False  [Reasoning] The image shows a colorful landsca...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de27f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "SAT_TRAIN_GENERATED_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT/train_generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9c3282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global image_idx_counter\n",
    "image_idx_counter = 0\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def base64_to_image(base64_str: str) -> Image.Image:\n",
    "    \"\"\"Convert a base64 string back to a PIL Image.\"\"\"\n",
    "    img_data = base64.b64decode(base64_str)\n",
    "    return Image.open(BytesIO(img_data))\n",
    "\n",
    "def deserialize_messages(serialized):\n",
    "    \"\"\"Convert base64-encoded images in messages back to PIL Images.\"\"\"\n",
    "    global image_idx_counter\n",
    "    deserialized = []\n",
    "    for msg in serialized:\n",
    "        new_msg = {\"role\": msg[\"role\"], \"content\": []}\n",
    "        for i, item in enumerate(msg[\"content\"]):\n",
    "            if item[\"type\"] == \"image\" and \"data\" in item:\n",
    "                # Reconstruct PIL image from base64 data\n",
    "                image = base64_to_image(item[\"data\"])\n",
    "                image_path = f\"{SAT_TRAIN_GENERATED_FOLDER}/images/image_{image_idx_counter}.png\"\n",
    "                image.save(image_path)\n",
    "                image_idx_counter += 1\n",
    "                new_msg[\"content\"].append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image_path\n",
    "                })\n",
    "                msg[\"content\"][i + 1][\"text\"] = \"<image>\" + msg[\"content\"][i + 1][\"text\"]\n",
    "            else:\n",
    "                new_msg[\"content\"].append(item)\n",
    "        deserialized.append(new_msg)\n",
    "    return deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3d10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'type': 'image', 'image': '/ocean/projects/cis250208p/shared/datasets/SAT/train_generated/images/image_0.png'}, {'type': 'text', 'text': \"<image>\\n### Situation Description\\nGiven an image and a spatial reasoning question, we need to all entities that are included in the question.\\n\\n# Example 1\\n[Question] You are standing at the airplane's position, facing where it is facing. Is the the person on your left or right?\\n[Detect] [airplane, person]\\n\\n# Examples 2\\n[Question] From the old man's perspective, is the person wearing a hat on the left of the green car?\\n[Detect] [old man, person wearing a hat, green car]\\n\\n# Examples 3\\n[Question] From the car's perspective, which is on the right side: the person or the tree?\\n[Detect] [car, person, tree]\\n\\n### Your Task\\nNow, given the question below, please identify the entities that are included in the question.\\n\\n[Question] From the camera's point of view, Considering the relative positions, is iron cheir above or below Doorway? A. below or B. above, give the letter of the correct answer.\\n[Detect]\\n\"}]}]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(os.path.join(SAT_TRAIN_GENERATED_FOLDER, \"conversation_1.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "deserialized = deserialize_messages(data[0][\"messages\"])\n",
    "print(deserialized)\n",
    "# deserialized[0][\"content\"][0][\"image\"].save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_data(entry):\n",
    "    processed_entry = {}\n",
    "    deserialized = deserialize_messages(entry[\"messages\"])\n",
    "    processed_entry[\"messages\"] = deserialized\n",
    "    processed_entry[\"response\"] = entry[\"response\"]\n",
    "    processed_entry[\"conv_type\"] = entry[\"conv_type\"]\n",
    "    return processed_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e2390bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1019 [00:32<07:24,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there are no separate gray rectangle sofa and green threecushion sofa in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 113/1019 [00:47<07:30,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered from the provided image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 258/1019 [01:32<02:09,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 304/1019 [01:40<02:22,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot answer the question as there is no doorway in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 378/1019 [01:55<02:49,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as posed because the red and green sections are part of a single object and are positioned side-by-side on the same horizontal plane, not one above or below the other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 464/1019 [02:17<01:02,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No square cardboard box is visible in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 523/1019 [02:32<01:33,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No brown wooden chair (marked b) is visible in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 617/1019 [02:51<01:20,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 629/1019 [02:53<00:51,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as posed because there is no point a in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 638/1019 [02:56<01:45,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no black chair with round backrest (marked a) in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 681/1019 [03:05<01:04,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no doorway (marked a) in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 803/1019 [03:35<00:22,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 910/1019 [03:57<00:13,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither A nor B can be definitively chosen as the objects are at the same depth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 926/1019 [04:00<00:13,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question cannot be answered as there is no doorway in the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1019/1019 [04:20<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6437684003925417\n",
      "656\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"SAT_labeled.jsonl\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "SAT_TRAIN_GENERATED_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT/train_generated_1\"\n",
    "\n",
    "correct_idx = []\n",
    "total_count = 0\n",
    "\n",
    "image_idx_counter = 329\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "files = os.listdir(SAT_TRAIN_GENERATED_FOLDER)\n",
    "files = [f for f in files if f.endswith(\".jsonl\")]\n",
    "\n",
    "total_count = len(files)\n",
    "for filename in tqdm(files):\n",
    "    idx = int(filename.split(\"_\")[-1].split(\".\")[0])\n",
    "    file_path = os.path.join(SAT_TRAIN_GENERATED_FOLDER, filename)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = []\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "        try:\n",
    "            answer_extracted = data[-1][\"response\"].split(\"[Answer]\")[1].strip()\n",
    "            answer_extracted = answer_extracted.split(\".\")[0].strip()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    \n",
    "        try:\n",
    "            pred_index = ord(answer_extracted) - ord('A')\n",
    "        except:\n",
    "            print(answer_extracted)\n",
    "            continue\n",
    "\n",
    "        if pred_index < 0 or pred_index >= len(ds[idx][\"answer_choices\"]):\n",
    "            continue\n",
    "        answer = ds[idx][\"answer_choices\"][pred_index]\n",
    "        if answer == ds[idx][\"correct_answer\"]:\n",
    "            correct_idx.append(idx)\n",
    "            for item in data:\n",
    "                processed_data.append(parse_image_data(item))\n",
    "            \n",
    "print(len(correct_idx)/total_count)\n",
    "print(len(correct_idx))\n",
    "print(total_count)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f79be404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_objects_of_interest': 656, 'detection_refinement': 1366, 'get_reference_viewer': 656, 'convert_to_ego': 656, 'perspective_visual': 656, 'abstract_to_real': 656}\n"
     ]
    }
   ],
   "source": [
    "output_data = []\n",
    "\n",
    "conv_type_counter = {\n",
    "}\n",
    "\n",
    "for item in processed_data:\n",
    "    \n",
    "    if item[\"conv_type\"] not in conv_type_counter:\n",
    "        conv_type_counter[item[\"conv_type\"]] = 0\n",
    "    conv_type_counter[item[\"conv_type\"]] += 1\n",
    "\n",
    "    entry = {\n",
    "        \"messages\": [],\n",
    "        \"images\": [],\n",
    "    }\n",
    "\n",
    "    for msg in item[\"messages\"]:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            for sub_item in msg[\"content\"]:\n",
    "                if sub_item[\"type\"] == \"image\":\n",
    "                    entry[\"images\"].append(sub_item[\"image\"])\n",
    "                elif sub_item[\"type\"] == \"text\":\n",
    "                    entry[\"messages\"].append({\n",
    "                        \"content\": sub_item[\"text\"],\n",
    "                        \"role\": \"user\"\n",
    "                    })\n",
    "                else:\n",
    "                    print(\"Unknown message type\")\n",
    "        elif msg[\"role\"] == \"system\":\n",
    "            if len(msg[\"content\"]) != 1:\n",
    "                print(\"ERROR\")\n",
    "\n",
    "            entry[\"messages\"].append({\n",
    "                \"content\": msg[\"content\"][0][\"text\"],\n",
    "                \"role\": \"assistant\"\n",
    "            })\n",
    "        else:\n",
    "            print(\"Unknown message role\")\n",
    "    \n",
    "    entry[\"messages\"].append({\n",
    "        \"content\": item[\"response\"],\n",
    "        \"role\": \"assistant\"\n",
    "    })\n",
    "        \n",
    "    output_data.append(entry)\n",
    "\n",
    "print(conv_type_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70caf367",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAT_TRAIN_GENERATED_FOLDER + \"/train_data.json\", \"w\") as f:\n",
    "    json.dump(output_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5e1e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3663\n"
     ]
    }
   ],
   "source": [
    "print(image_idx_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets/SAT\"\n",
    "DATASET_FOLDER = \"/ocean/projects/cis250208p/shared/datasets\"\n",
    "# with open(os.path.join(SAT_DATASET_FOLDER, \"data.json\"), \"w\") as f:\n",
    "\n",
    "merge_data = []\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"train_generated/train_data.json\"), \"r\") as f:\n",
    "    merge_data.extend(json.load(f))\n",
    "\n",
    "with open(os.path.join(SAT_DATASET_FOLDER, \"train_generated_1/train_data.json\"), \"r\") as f:\n",
    "    merge_data.extend(json.load(f))\n",
    "\n",
    "with open(os.path.join(DATASET_FOLDER, \"data.json\"), \"w\") as f:\n",
    "    json.dump(merge_data, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
