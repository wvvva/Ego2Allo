{
  "os": "Linux-4.18.0-553.22.1.el8_10.x86_64-x86_64-with-glibc2.28",
  "python": "CPython 3.10.19",
  "startedAt": "2025-11-25T14:58:03.255427Z",
  "program": "/jet/home/vwei/Ego2Allo/train/rl/Qwen3_VL_python_pls_work.py",
  "codePath": "train/rl/Qwen3_VL_python_pls_work.py",
  "codePathLocal": "train/rl/Qwen3_VL_python_pls_work.py",
  "git": {
    "remote": "https://github.com/wvvva/Ego2Allo.git",
    "commit": "0890ab849f5694863b2d714d736c8a3378d42fce"
  },
  "email": "vwei2@andrew.cmu.edu",
  "root": "/jet/home/vwei/Ego2Allo",
  "host": "v004.ib.bridges2.psc.edu",
  "executable": "/jet/home/vwei/Ego2Allo/unsloth/bin/python",
  "cpu_count": 40,
  "cpu_count_logical": 40,
  "gpu": "Tesla V100-SXM2-32GB",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "315926315008",
      "used": "47130779648"
    }
  },
  "memory": {
    "total": "540673691648"
  },
  "gpu_nvidia": [
    {
      "name": "Tesla V100-SXM2-32GB",
      "memoryTotal": "34359738368",
      "cudaCores": 5120,
      "architecture": "Volta",
      "uuid": "GPU-f3064da9-8691-edf2-5342-a04c0f40cbe0"
    }
  ],
  "cudaVersion": "12.6",
  "slurm": {
    "export_env": "ALL",
    "job_id": "36203814"
  },
  "writerId": "h25v88e8w9zsqmy8qli60vnjtdv3pvnq"
}