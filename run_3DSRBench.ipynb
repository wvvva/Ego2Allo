{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a7041c",
   "metadata": {},
   "source": [
    "## 0. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fdfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "667ddf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/ocean/projects/cis250208p/shared/datasets\"\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"ccvl/3DSRBench\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11bcf622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['index', 'question', 'A', 'B', 'C', 'D', 'answer', 'category', 'image_source', 'image_url'],\n",
      "        num_rows: 5157\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75323e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a1166",
   "metadata": {},
   "source": [
    "## 1.APC Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a4a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"  # or \"egl\" if CUDA drivers support EGL\n",
    "# os.environ[\"DISPLAY\"] = \":0\"\n",
    "\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"   # use EGL instead of OSMesa for NVIDIA drivers\n",
    "os.environ.pop(\"DISPLAY\", None)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03dfe030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 24 10:52:54 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:15:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             54W /  300W |   32412MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     27064      C   ...inga/envs/apc_vlm_env/bin/python3.9      23086MiB |\n",
      "|    0   N/A  N/A     50536      C   ...inga/envs/apc_vlm_env/bin/python3.9       9322MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 50536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ab0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c1fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"DISPLAY\"] =':1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # set GPU device\n",
    "sys.path.append(\"apc/vision_modules\")\n",
    "import yaml\n",
    "import re\n",
    "import requests\n",
    "from box import Box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "# import APC pipeline\n",
    "from apc.apc_pipeline import APC\n",
    "from apc.utils import visualize_conversation, create_image_with_text\n",
    "\n",
    "# set device\n",
    "device_vlm = \"cuda:0\"\n",
    "device_vision = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072e8cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded config Qwen/Qwen2.5-VL-7B-Instruct\n",
      "[INFO] Loaded config hidden_size=3584, model_type=qwen2_5_vl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdb67f1649346e4bc42bde0cf254dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "2025-10-24 10:59:47 INFO [apc.apc_pipeline] [APC] Initialized VLM model: qwenvl2_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model type: qwen2_5_vl\n",
      "[INFO] Hidden size: 3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 11:00:16 INFO [depth_pro.network.vit_factory] Module(\n",
      "  (model): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (patch_drop): Identity()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): Sequential(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (12): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (13): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (14): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (15): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (16): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (17): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (18): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (19): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (20): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (21): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (22): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (23): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n",
      "2025-10-24 11:00:19 INFO [depth_pro.network.vit_factory] Module(\n",
      "  (model): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (patch_drop): Identity()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): Sequential(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (12): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (13): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (14): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (15): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (16): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (17): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (18): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (19): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (20): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (21): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (22): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (23): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n",
      "2025-10-24 11:00:22 INFO [depth_pro.network.vit_factory] Module(\n",
      "  (model): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (patch_drop): Identity()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): Sequential(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (12): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (13): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (14): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (15): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (16): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (17): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (18): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (19): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (20): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (21): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (22): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (23): Block(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n",
      "FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/ocean/projects/cis250208p/shared/models/vision_modules/checkpoints/models--facebook--dinov2-large/.no_exist/47b73eefe95e8d44ec3623f8890bd894b6ea2d6c/processor_config.json'\n",
      "2025-10-24 11:00:48 ERROR [huggingface_hub.file_download] Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/ocean/projects/cis250208p/shared/models/vision_modules/checkpoints/models--facebook--dinov2-large/.no_exist/47b73eefe95e8d44ec3623f8890bd894b6ea2d6c/processor_config.json'\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "2025-10-24 11:00:48 INFO [apc.apc_pipeline] [APC] Initialized vision modules\n",
      "2025-10-24 11:00:48 INFO [apc.apc_pipeline] [APC] Initialized prompt parser\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "config_path = \"apc/configs/qwenvl2_5_7b_instruct.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = Box(config)\n",
    "\n",
    "# load APC pipeline\n",
    "apc = APC(config, device_vlm=device_vlm, device_vision=device_vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9d2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url):\n",
    "    response = requests.get(image_url, timeout=20)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\").resize((512, 512))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c6e625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 11:03:29 INFO [OpenGL.acceleratesupport] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
     ]
    }
   ],
   "source": [
    "import pyrender\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def path3d_to_trimesh(path, radius=0.002, color=[255, 255, 255, 255]):\n",
    "    \"\"\"\n",
    "    Convert a trimesh.path.Path3D into a small-radius tube mesh for rendering.\n",
    "    Handles both old/new Trimesh APIs (vertices vs points).\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    for entity in path.entities:\n",
    "        # Find vertex indices robustly\n",
    "        if hasattr(entity, \"vertices\"):\n",
    "            idx = entity.vertices\n",
    "        elif hasattr(entity, \"points\"):\n",
    "            idx = entity.points\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Ensure valid indices\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            start = np.array(path.vertices[idx[0]])\n",
    "            end = np.array(path.vertices[idx[1]])\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Skip degenerate lines\n",
    "        if np.allclose(start, end):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # NOTE: cylinder() expects two 3D points (shape (2,3))\n",
    "            cyl = trimesh.creation.cylinder(radius=radius, segment=np.vstack([start, end]))\n",
    "            cyl.visual.vertex_colors = np.tile(color, (len(cyl.vertices), 1))\n",
    "            segments.append(cyl)\n",
    "        except Exception as e:\n",
    "            print(f\" Cylinder creation failed for Path3D segment: {e}\")\n",
    "\n",
    "    if not segments:\n",
    "        return None\n",
    "\n",
    "    return trimesh.util.concatenate(segments)\n",
    "    \n",
    "def save_image_with_pyrender(scene_or_mesh, resolution=(512, 512)):\n",
    "    \"\"\"\n",
    "    Robust EGL-based renderer for Trimesh scenes using Pyrender.\n",
    "    Works safely even if the scene includes Path3D, PointCloud, or face-colored meshes.\n",
    "    Returns PNG bytes.\n",
    "    \"\"\"\n",
    "    # Normalize input\n",
    "    if isinstance(scene_or_mesh, trimesh.Trimesh):\n",
    "        scene = trimesh.Scene(scene_or_mesh)\n",
    "    else:\n",
    "        scene = scene_or_mesh\n",
    "\n",
    "    render_scene = pyrender.Scene()\n",
    "\n",
    "    # Iterate through all geometries in the scene\n",
    "    for name, geom in scene.geometry.items():\n",
    "        if isinstance(geom, trimesh.Trimesh):\n",
    "            try:\n",
    "                # Determine if the mesh has per-face colors\n",
    "                has_face_colors = (\n",
    "                    hasattr(geom, \"visual\")\n",
    "                    and hasattr(geom.visual, \"face_colors\")\n",
    "                    and geom.visual.face_colors is not None\n",
    "                    and len(geom.visual.face_colors) == len(geom.faces)\n",
    "                )\n",
    "\n",
    "                # Convert face colors  vertex colors for smooth shading\n",
    "                if has_face_colors:\n",
    "                    geom = geom.copy()\n",
    "                    try:\n",
    "                        geom.visual = geom.visual.to_vertex_colors()\n",
    "                    except Exception:\n",
    "                        # Some visuals may not support conversion cleanly\n",
    "                        has_face_colors = True  # fallback to flat shading\n",
    "\n",
    "                mesh_render = pyrender.Mesh.from_trimesh(\n",
    "                    geom,\n",
    "                    smooth=not has_face_colors\n",
    "                )\n",
    "                render_scene.add(mesh_render)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" Skipping mesh {name}: {e}\")\n",
    "        elif isinstance(geom, trimesh.path.Path3D):\n",
    "            try:\n",
    "                path_mesh = path3d_to_trimesh(geom, radius=0.002)\n",
    "                if path_mesh is not None:\n",
    "                    mesh_render = pyrender.Mesh.from_trimesh(path_mesh, smooth=False)\n",
    "                    render_scene.add(mesh_render)\n",
    "            except Exception as e:\n",
    "                print(f\" Failed to render Path3D '{name}': {e}\")\n",
    "        else:\n",
    "            print(f\" Skipping non-mesh geometry: {name} ({type(geom).__name__})\")\n",
    "\n",
    "    # Add a basic light\n",
    "    light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "    render_scene.add(light, pose=np.eye(4))\n",
    "\n",
    "    # Simple camera\n",
    "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "    render_scene.add(camera, pose=[[1,0,0,0],\n",
    "                                   [0,1,0,0],\n",
    "                                   [0,0,1,2.5],\n",
    "                                   [0,0,0,1]])\n",
    "\n",
    "    # Offscreen render via EGL\n",
    "    r = pyrender.OffscreenRenderer(*resolution)\n",
    "    color, _ = r.render(render_scene)\n",
    "    r.delete()\n",
    "\n",
    "    # Return PNG bytes\n",
    "    buf = io.BytesIO()\n",
    "    Image.fromarray(color).save(buf, format=\"PNG\")\n",
    "    return buf.getvalue()\n",
    "\n",
    "trimesh.Scene.save_image = save_image_with_pyrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# import torch\n",
    "\n",
    "# # Suppress all general warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Optionally, suppress only specific warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# # For torch checkpoint warning specifically\n",
    "# import torch.utils.checkpoint\n",
    "# torch.utils.checkpoint.use_reentrant = False  # explicitly set new default (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(42)\n",
    "# indices = random.sample(range(len(ds)), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Balanced dataset size: 180\n",
      "['multi_object_parallel', 'orientation_viewpoint', 'multi_object_viewpoint_towards_object', 'orientation_viewpoint', 'multi_object_same_direction', 'orientation_in_front_of', 'orientation_on_the_left', 'multi_object_closer_to', 'multi_object_parallel', 'height_higher', 'location_above', 'orientation_viewpoint', 'orientation_on_the_left', 'multi_object_closer_to', 'orientation_in_front_of', 'multi_object_same_direction', 'orientation_viewpoint', 'location_closer_to_camera', 'height_higher', 'orientation_viewpoint']\n"
     ]
    }
   ],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# # how many total samples to select\n",
    "# total_samples = 180\n",
    "\n",
    "# # unique categories\n",
    "# categories = list(set(ds[\"category\"]))\n",
    "# samples_per_cat = total_samples // len(categories)\n",
    "\n",
    "# balanced_subsets = []\n",
    "\n",
    "# for cat in categories:\n",
    "#     subset = ds.filter(lambda x: x[\"category\"] == cat)\n",
    "#     n = min(samples_per_cat, len(subset))  # handle small categories\n",
    "#     subset = subset.shuffle(seed=42).select(range(n))\n",
    "#     balanced_subsets.append(subset)\n",
    "\n",
    "# # combine them and shuffle the final set\n",
    "# balanced_ds = concatenate_datasets(balanced_subsets).shuffle(seed=42)\n",
    "\n",
    "# print(f\" Balanced dataset size: {len(balanced_ds)}\")\n",
    "# print(balanced_ds['category'][:20])  # preview the categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e793e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599d73253e364895837c0a13cbd89f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# balanced_ds.save_to_disk(\"test_dataset_150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ee0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"test_dataset_150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de674c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"test_dataset_150.txt\", \"w\") as f:\n",
    "#     for idx in balanced_ds[\"index\"]:\n",
    "#         f.write(str(idx) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ccc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = balanced_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8065dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single(i, example):\n",
    "    image_url = example[\"image_url\"]\n",
    "    question = example[\"question\"]\n",
    "    options = [example[\"A\"], example[\"B\"], example[\"C\"], example[\"D\"]]\n",
    "    correct = example[\"answer\"]\n",
    "    category = example[\"category\"]\n",
    "\n",
    "    # Download image\n",
    "    image = download_image(image_url)\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.title(f\"Index {i}  Category: {example['category']}\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # Build prompt\n",
    "    valid_options = [(chr(65 + j), opt) for j, opt in enumerate(options) if opt and str(opt).strip()]\n",
    "    options_text = \" or \".join([f\"{label}. {opt}\" for label, opt in valid_options])\n",
    "    prompt = f\"From the camera's point of view, {question.strip()} {options_text}, give the letter of the correct answer.\"\n",
    "\n",
    "    # print(\"Prompt:\")\n",
    "    # print(prompt)\n",
    "\n",
    "    # Directory for saving intermediate results\n",
    "    save_dir = f\"outputs/benchmark/{category}_{i}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    image_with_text = create_image_with_text(image, \"[Q] \" + prompt, fontsize=20)\n",
    "    # image_with_text.save(f\"outputs/benchmark/3DSRBench_{i}_prompt.png\")\n",
    "\n",
    "    # Run APC pipeline\n",
    "    response_text, conv_history = apc.run_apc(\n",
    "        image,\n",
    "        prompt,\n",
    "        trace_save_dir=save_dir,\n",
    "        perspective_prompt_type=\"visual\",\n",
    "        visualize_trace=False,\n",
    "        visualize_scene_abstraction=False,\n",
    "        return_conv_history=False,\n",
    "        logging=False,\n",
    "    )\n",
    "\n",
    "    # print(\"Response\", response_text)\n",
    "    # Extract predicted answer (search for 'A', 'B', 'C', 'D')\n",
    "    match = re.search(r\"\\b([ABCD])\\b\", response_text.upper())\n",
    "    pred_letter = match.group(1) if match else None\n",
    "\n",
    "    # print(len(conv_history))\n",
    "    # for i in range(len(conv_history)):\n",
    "        # print(conv_history[i])\n",
    "\n",
    "    # conv_viz = visualize_conversation(\n",
    "    #     conv_history,\n",
    "    #     width=900,\n",
    "    #     row_gap=0,\n",
    "    #     font_size=13,\n",
    "    #     image_max_width=180,\n",
    "    #     output_path=os.path.join(save_dir, \"conversation_viz.png\")\n",
    "    # )\n",
    "\n",
    "    return {\n",
    "        \"index\": example[\"index\"],\n",
    "        \"category\": category,\n",
    "        \"question\": question,\n",
    "        \"prediction\": pred_letter,\n",
    "        \"answer\": correct,\n",
    "        \"is_correct\": pred_letter == correct,\n",
    "        \"response_text\": response_text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a16fd8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    results = []\n",
    "\n",
    "    for i, example in enumerate(tqdm(ds, desc=\"Evaluating 3DSRBench\")):\n",
    "        results.append(run_single(i, ds[i]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96f2e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['index', 'question', 'A', 'B', 'C', 'D', 'answer', 'category', 'image_source', 'image_url'],\n",
      "    num_rows: 180\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f231ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = run_single(0, ds[0])\n",
    "# results = run()\n",
    "# df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8617517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 3DSRBench:   0%|                                            | 0/180 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "Evaluating 3DSRBench: 100%|| 180/180 [1:12:37<00:00, 24.21s/it]\n",
      "Evaluating 3DSRBench: 100%|| 180/180 [1:34:34<00:00, 31.52s/it]\n",
      "Evaluating 3DSRBench:   1%|                    | 1/180 [00:42<2:06:51, 42.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m      4\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3DSRBench_raw_predictions_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(ds, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating 3DSRBench\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m----> 5\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m, in \u001b[0;36mrun_single\u001b[0;34m(i, example)\u001b[0m\n\u001b[1;32m     28\u001b[0m image_with_text \u001b[38;5;241m=\u001b[39m create_image_with_text(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Q] \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m prompt, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# image_with_text.save(f\"outputs/benchmark/3DSRBench_{i}_prompt.png\")\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Run APC pipeline\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m response_text, conv_history \u001b[38;5;241m=\u001b[39m \u001b[43mapc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_apc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperspective_prompt_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvisual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualize_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualize_scene_abstraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_conv_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# print(\"Response\", response_text)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Extract predicted answer (search for 'A', 'B', 'C', 'D')\u001b[39;00m\n\u001b[1;32m     45\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb([ABCD])\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_text\u001b[38;5;241m.\u001b[39mupper())\n",
      "File \u001b[0;32m~/project/APC-VLM-idl-baseline/apc/apc_pipeline.py:595\u001b[0m, in \u001b[0;36mAPC.run_apc\u001b[0;34m(self, image, prompt, trace_save_dir, perspective_prompt_type, visualize_trace, visualize_scene_abstraction, render_whole_scene, return_conv_history, options, logging)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# Run 3D scene abstraction (from camera's perspective)\u001b[39;00m\n\u001b[1;32m    594\u001b[0m abstract_scene_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 595\u001b[0m abstract_scene_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_scene_abstraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs_of_interest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mapc_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Scene Abstraction] Abstracted scene (camera\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms perspective): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mabstract_scene_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------ #\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# [2] Perspective Change\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------ #\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# Extract the reference (target) viewer\u001b[39;00m\n",
      "File \u001b[0;32m~/project/APC-VLM-idl-baseline/apc/apc_pipeline.py:292\u001b[0m, in \u001b[0;36mAPC.do_scene_abstraction\u001b[0;34m(self, image, objects_of_interest, **apc_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m selected_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdetection\u001b[38;5;241m.\u001b[39muse_vlm_refinement:\n\u001b[0;32m--> 292\u001b[0m     box2D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetection_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_detection_refinement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvlm_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mboxes_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mapc_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     box2D \u001b[38;5;241m=\u001b[39m boxes[selected_idx]\n",
      "File \u001b[0;32m~/project/APC-VLM-idl-baseline/apc/vision_modules/detection.py:167\u001b[0m, in \u001b[0;36mDetectionModule.run_detection_refinement\u001b[0;34m(self, vlm_model, image, category, boxes_output, **apc_args)\u001b[0m\n\u001b[1;32m    161\u001b[0m messages \u001b[38;5;241m=\u001b[39m add_message(\n\u001b[1;32m    162\u001b[0m     [], role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    163\u001b[0m     text\u001b[38;5;241m=\u001b[39mprompt_refinement, image\u001b[38;5;241m=\u001b[39mcandidate_image\n\u001b[1;32m    164\u001b[0m )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Query VLM\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mvlm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# print(f\"* [INFO] Response for VLM detection refinement: {response}\")\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Get the selected index\u001b[39;00m\n\u001b[1;32m    171\u001b[0m selected_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/project/APC-VLM-idl-baseline/apc/vlms/vlm_qwenvl2_5.py:111\u001b[0m, in \u001b[0;36mModelQwenVL2_5.process_messages\u001b[0;34m(self, messages, max_new_tokens, do_sample, temperature)\u001b[0m\n\u001b[1;32m    108\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Run the model\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvlm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m generated_ids_trimmed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    118\u001b[0m     out_ids[\u001b[38;5;28mlen\u001b[39m(in_ids) :] \n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m in_ids, out_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs\u001b[38;5;241m.\u001b[39minput_ids, generated_ids)\n\u001b[1;32m    120\u001b[0m ]\n\u001b[1;32m    121\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m    122\u001b[0m     generated_ids_trimmed, \n\u001b[1;32m    123\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    124\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    125\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/ocean/projects/cis250208p/ydinga/envs/apc_vlm_env/lib/python3.9/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ocean/projects/cis250208p/ydinga/envs/apc_vlm_env/lib/python3.9/site-packages/transformers/generation/utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[0;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m ):\n",
      "File \u001b[0;32m/ocean/projects/cis250208p/ydinga/envs/apc_vlm_env/lib/python3.9/site-packages/transformers/generation/utils.py:2779\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2777\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 2779\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2780\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m   2781\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n",
      "File \u001b[0;32m/ocean/projects/cis250208p/ydinga/envs/apc_vlm_env/lib/python3.9/site-packages/transformers/generation/utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin._has_unfinished_sequences\u001b[0;34m(self, this_peer_finished, synced_gpus, device)\u001b[0m\n\u001b[1;32m   2595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m this_peer_finished_flag\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   2596\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    results = run()\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(f\"3DSRBench_raw_predictions_{i}.csv\", index=False)\n",
    "\n",
    "# !scancel -u vwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"3DSRBench_raw_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a6bb0",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a33b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"3DSRBench_raw_predictions_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b68c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "# ---- Overall accuracy ----\n",
    "metrics[\"overall_accuracy\"] = df[\"is_correct\"].mean()\n",
    "\n",
    "# # ---- Standard deviation of correctness (robustness) ----\n",
    "# metrics[\"std_dev_accuracy\"] = df[\"is_correct\"].std()\n",
    "\n",
    "# ---- Category-wise accuracy ----\n",
    "cat_acc = df.groupby(\"category\")[\"is_correct\"].mean().to_dict()\n",
    "for cat, acc in cat_acc.items():\n",
    "    metrics[f\"acc_{cat}\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95d2e6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation Complete!\n",
      "                                                  0\n",
      "overall_accuracy                           0.455556\n",
      "acc_height_higher                          0.400000\n",
      "acc_location_above                         0.733333\n",
      "acc_location_closer_to_camera              0.200000\n",
      "acc_location_next_to                       0.666667\n",
      "acc_multi_object_closer_to                 0.333333\n",
      "acc_multi_object_facing                    0.133333\n",
      "acc_multi_object_parallel                  0.600000\n",
      "acc_multi_object_same_direction            0.666667\n",
      "acc_multi_object_viewpoint_towards_object  0.266667\n",
      "acc_orientation_in_front_of                0.666667\n",
      "acc_orientation_on_the_left                0.533333\n",
      "acc_orientation_viewpoint                  0.266667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =======================\n",
    "# Save results\n",
    "# =======================\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(\"3DSRBench_metrics_summary_4.csv\", index=False)\n",
    "\n",
    "print(\"\\n Evaluation Complete!\")\n",
    "print(metrics_df.T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
