{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a7041c",
   "metadata": {},
   "source": [
    "## 0. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fdfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset, Features, Value, Image, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667ddf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/ocean/projects/cis250208p/shared/datasets/SAT/SAT_labeled.jsonl\"\n",
    "\n",
    "train_data = []\n",
    "\n",
    "labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        train_data.append(json.loads(line))\n",
    "        train_data[-1][\"index\"] = i  # add index field\n",
    "\n",
    "        choices = train_data[-1].get(\"answer_choices\", [])\n",
    "        train_data[-1].pop(\"answer_choices\")\n",
    "        for i, label in enumerate(labels):\n",
    "            train_data[-1][label] = choices[i] if i < len(choices) else None\n",
    "\n",
    "\n",
    "features = Features({\n",
    "    \"index\": Value(\"int32\"),\n",
    "    \"image\": Image(),  # will load image paths or binary image data\n",
    "    \"question\": Value(\"string\"),\n",
    "    \"A\": Value(\"string\"),\n",
    "    \"B\": Value(\"string\"),\n",
    "    \"C\": Value(\"string\"),\n",
    "    \"D\": Value(\"string\"),\n",
    "    \"correct_answer\": Value(\"string\"),\n",
    "    \"category\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "ds = Dataset.from_list(train_data, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b82bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'question', 'correct_answer', 'category', 'index', 'A', 'B', 'C', 'D'],\n",
      "    num_rows: 6494\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bcf622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['index', 'question', 'A', 'B', 'C', 'D', 'answer', 'category', 'image_source', 'image_url'],\n",
      "        num_rows: 5157\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a1166",
   "metadata": {},
   "source": [
    "## 1.APC Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a4a372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"  # or \"egl\" if CUDA drivers support EGL\n",
    "# os.environ[\"DISPLAY\"] = \":0\"\n",
    "\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"   # use EGL instead of OSMesa for NVIDIA drivers\n",
    "os.environ.pop(\"DISPLAY\", None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03dfe030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 21 22:56:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:16:00.0 Off |                    0 |\n",
      "| N/A   28C    P0             40W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ab0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"DISPLAY\"] =':1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # set GPU device\n",
    "sys.path.append(\"apc/vision_modules\")\n",
    "import yaml\n",
    "import re\n",
    "import requests\n",
    "from box import Box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "# import APC pipeline\n",
    "from apc.apc_pipeline import APC\n",
    "from apc.utils import visualize_conversation, create_image_with_text\n",
    "\n",
    "# set device\n",
    "device_vlm = \"cuda:0\"\n",
    "device_vision = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e8cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a2543e820e483fbde8a5f645dbb669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load config\n",
    "config_path = \"apc/configs/qwenvl2_5_7b_instruct.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config = Box(config)\n",
    "\n",
    "# load APC pipeline\n",
    "apc = APC(config, device_vlm=device_vlm, device_vision=device_vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url):\n",
    "    response = requests.get(image_url, timeout=20)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\").resize((512, 512))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 3DSRBench:   0%|                                    | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_apc() missing 1 required positional argument: 'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Run APC pipeline\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m response_text, _ \u001b[38;5;241m=\u001b[39m \u001b[43mAPC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_apc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperspective_prompt_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvisual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualize_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualize_scene_abstraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_conv_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(\"Response\", response_text)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Extract predicted answer (search for 'A', 'B', 'C', 'D')\u001b[39;00m\n\u001b[1;32m     42\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb([ABCD])\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_text\u001b[38;5;241m.\u001b[39mupper())\n",
      "\u001b[0;31mTypeError\u001b[0m: run_apc() missing 1 required positional argument: 'prompt'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, example in enumerate(tqdm(ds.select(range(100)), desc=\"Evaluating SAT\")):\n",
    "    image = [img.convert(\"RGB\").resize((512, 512)) for img in example[\"image\"]]\n",
    "    question = example[\"question\"]\n",
    "    options = [example[\"A\"], example[\"B\"], example[\"C\"], example[\"D\"]]\n",
    "    correct = example[\"correct_answer\"]\n",
    "    category = example[\"category\"]\n",
    "\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.title(f\"Index {i} — Category: {example['category']}\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = f\"From the camera's point of view, {question}\\nOptions:\\nA. {options[0]}\\nB. {options[1]}\\nC. {options[2]}\\nD. {options[3]}\\nPlease answer with only one letter (A/B/C/D).\"\n",
    "\n",
    "    # print(\"Prompt:\")\n",
    "    # print(prompt)\n",
    "\n",
    "    # Directory for saving intermediate results\n",
    "    save_dir = f\"outputs/benchmark/{category}_{i}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Run APC pipeline\n",
    "    response_text, _ = apc.run_apc(\n",
    "        image,\n",
    "        prompt,\n",
    "        trace_save_dir=save_dir,\n",
    "        perspective_prompt_type=\"visual\",\n",
    "        visualize_trace=False,\n",
    "        visualize_scene_abstraction=False,\n",
    "        return_conv_history=False,\n",
    "        logging=False,\n",
    "    )\n",
    "\n",
    "    # print(\"Response\", response_text)\n",
    "    # Extract predicted answer (search for 'A', 'B', 'C', 'D')\n",
    "    match = re.search(r\"\\b([ABCD])\\b\", response_text.upper())\n",
    "    pred_letter = match.group(1) if match else None\n",
    "\n",
    "    results.append({\n",
    "        \"index\": example[\"index\"],\n",
    "        \"category\": category,\n",
    "        \"question\": question,\n",
    "        \"prediction\": pred_letter,\n",
    "        \"answer\": correct,\n",
    "        \"is_correct\": pred_letter == correct,\n",
    "        \"response_text\": response_text,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"3DSRBench_raw_predictions.csv\", index=False)\n",
    "\n",
    "# =======================\n",
    "# Compute metrics\n",
    "# =======================\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "# ---- Overall accuracy ----\n",
    "metrics[\"overall_accuracy\"] = df[\"is_correct\"].mean()\n",
    "\n",
    "# ---- Standard deviation of correctness (robustness) ----\n",
    "metrics[\"std_dev_accuracy\"] = df[\"is_correct\"].std()\n",
    "\n",
    "# ---- Category-wise accuracy ----\n",
    "cat_acc = df.groupby(\"category\")[\"is_correct\"].mean().to_dict()\n",
    "for cat, acc in cat_acc.items():\n",
    "    metrics[f\"acc_{cat}\"] = acc\n",
    "\n",
    "# ---- Prediction noise ----\n",
    "# Approximation: frequency of inconsistent answers across paraphrased / symmetric questions\n",
    "# You can tag similar questions manually or heuristically by identical image_source + similar wording\n",
    "def estimate_prediction_noise(df):\n",
    "    grouped = df.groupby(\"image_source\")\n",
    "    noise_values = []\n",
    "    for _, g in grouped:\n",
    "        if len(g) > 1:\n",
    "            acc_var = g[\"is_correct\"].std()\n",
    "            if not np.isnan(acc_var):\n",
    "                noise_values.append(acc_var)\n",
    "    return np.mean(noise_values) if noise_values else 0.0\n",
    "\n",
    "metrics[\"prediction_noise\"] = estimate_prediction_noise(df)\n",
    "\n",
    "# ---- Spatial symmetry / opposite consistency ----\n",
    "# Simple heuristic: if question mentions \"left\" and another mentions \"right\" for same image_source\n",
    "def estimate_spatial_consistency(df):\n",
    "    left_q = df[df[\"question\"].str.contains(\"left\", case=False, na=False)]\n",
    "    right_q = df[df[\"question\"].str.contains(\"right\", case=False, na=False)]\n",
    "    consistency_pairs = 0\n",
    "    total_pairs = 0\n",
    "    for _, l in left_q.iterrows():\n",
    "        r_matches = right_q[right_q[\"image_source\"] == l[\"image_source\"]]\n",
    "        for _, r in r_matches.iterrows():\n",
    "            total_pairs += 1\n",
    "            if l[\"prediction\"] != r[\"prediction\"]:\n",
    "                consistency_pairs += 1\n",
    "    if total_pairs == 0:\n",
    "        return np.nan\n",
    "    return 1 - (consistency_pairs / total_pairs)\n",
    "\n",
    "metrics[\"spatial_consistency\"] = estimate_spatial_consistency(df)\n",
    "\n",
    "# =======================\n",
    "# Save results\n",
    "# =======================\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(\"3DSRBench_metrics_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Evaluation Complete!\")\n",
    "print(metrics_df.T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
